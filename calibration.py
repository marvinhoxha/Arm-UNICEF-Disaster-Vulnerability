import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
from PIL import Image
import re
import matplotlib.patches as patches
from ultralytics import YOLO
import os
import yaml
import json
from tqdm import tqdm
import mlflow
from ultralytics import settings
import torch
import os
from collections import defaultdict

os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

# Update a setting
settings.update({"mlflow": True})

model = YOLO('yolov8n.pt')

EPOCHS = 200
BATCH_SIZE = 32
OPTIMIZER = "auto"
SEED = 42
NAME = f"Arm_Yolo_{EPOCHS}"
DEVICE = [0]
VERBOSE = False
RESUME = False
PATIENCE = 20
img_height = 512
img_width = 512

def get_classes_count(pred_json: str):
    classes_count = defaultdict(int)
    for j in json.loads(pred_json):
        classes_count[j['class']] += 1
    return dict(classes_count)  # Convert defaultdict back to dict for compatibility

# Function to filter results based on a general threshold (e.g., very low threshold)
def filter_results(results, threshold=0.1):
    filtered_boxes = []
    for box in results[0].boxes:
        if box.conf >= threshold:
            filtered_boxes.append(box)
    return filtered_boxes

# Calibration function to compute probabilities for different intervals
def calibrate_probabilities(validation_data, model, intervals=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]):
    calibration = {cls: {interval: [] for interval in intervals[:-1]} for cls in range(3)}
    
    for index, row in tqdm(validation_data.iterrows(), total=len(validation_data)):
        pred = model.predict(f"Data/val/images/{row['image_id']}.tif", iou=0.7, conf=0.1)
        for box in pred[0].boxes:
            class_id = int(box.cls)
            confidence = float(box.conf)
            true_label = int(row['category_id'])  # Assuming 'category_id' is the true label
            
            for i in range(len(intervals) - 1):
                if intervals[i] <= confidence < intervals[i+1]:
                    calibration[class_id][intervals[i]].append(1 if true_label == class_id else 0)
    
    probabilities = {cls: {interval: 0 for interval in intervals[:-1]} for cls in range(3)}
    for cls in calibration:
        for interval in calibration[cls]:
            if calibration[cls][interval]:
                probabilities[cls][interval] = sum(calibration[cls][interval]) / len(calibration[cls][interval])
            else:
                probabilities[cls][interval] = 0
    
    return probabilities

# Function to get calibrated probabilities
def get_calibrated_prob(conf, class_id, probabilities, intervals=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]):
    for i in range(len(intervals) - 1):
        if intervals[i] <= conf < intervals[i+1]:
            return probabilities[class_id][intervals[i]]
    return 0

# Function to generate the submission file with calibrated probabilities
def generate_submission_file(test, model, probabilities, submission_file):
    submission_df = pd.DataFrame(columns=["image_id", "Target"])
    for index, row in tqdm(test.iterrows(), total=len(test)):
        pred = model.predict(f"Data/val/images/{row['image_id']}.tif", iou=0.7, conf=0.1)
        filtered_boxes = filter_results(pred)
        
        pred_counts = {0: 0, 1: 0, 2: 0}
        for box in filtered_boxes:
            class_id = int(box.cls)
            calibrated_prob = get_calibrated_prob(float(box.conf), class_id, probabilities)
            pred_counts[class_id] += calibrated_prob
        
        df = pd.DataFrame({
            "image_id": [f"{row['image_id']}_1", f"{row['image_id']}_2", f"{row['image_id']}_3"],
            "Target": [pred_counts.get(0, 0), pred_counts.get(1, 0), pred_counts.get(2, 0)]
        }, columns=["image_id", "Target"])
        
        submission_df = pd.concat([submission_df, df], axis=0)
    
    submission_df.to_csv(submission_file, index=False)

def train():
    """Prepare data for training"""
    validation_data = pd.read_csv("Data/Validation_Images.csv")
    test = pd.read_csv("Data/Unique_Image_IDs_Val.csv")
    mlflow.autolog()
    torch.cuda.empty_cache()
    model = YOLO('200epochs.pt')
    
    # Calibrate probabilities using validation data
    probabilities = calibrate_probabilities(validation_data, model)

    # Generate submission file using calibrated probabilities
    file = 'Data/Validation_prediction5.csv'
    generate_submission_file(test, model, probabilities, file)

if __name__ == "__main__":
    train()
